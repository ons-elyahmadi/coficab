mape_value <- mape(last_22_real[, 2], last_22_forecast$Forecast)
# Extraire la dernière date des prévisions
last_forecast_date <- tail(last_22_forecast$date, 1)
# Afficher les résultats
cat("MAE:", mae_value, "\n")
cat("RMSE:", rmse_value, "\n")
cat("R²:", r2_value, "\n")
cat("PMAE:", pmae_value, "\n")
cat("MSE:", mse_value, "\n")
cat("MAPE:", mape_value, "\n")
cat("Last Forecast Date:", last_forecast_date, "\n")
# Création d'un data frame pour les métriques avec la dernière date des prévisions
metrics_data <- data.frame(Date = last_forecast_date,
MAE = mae_value,
RMSE = rmse_value,
MSE = mse_value,
MAPE = mape_value)
# Sauvegarde des métriques dans un fichier spécifique
write.csv(metrics_data, file = "C:/Users/HP/Downloads/Predicting_Metal_Cost_with_R-master-20240318T152350Z-001/Predicting_Metal_Cost_with_R-master/data/metrics_CopperLME.csv", row.names = FALSE)
# Charger les bibliothèques nécessaires
library(forecast)
library(tseries)
library(ggplot2)
library(rvest)
library(dplyr)
library(rvest)
library(stringr)
library(lubridate)
# URL de la page à scraper
url <- 'https://www.ecb.europa.eu/ecb/contacts/working-hours/html/index.fr.html'
# Lire le contenu HTML de l'URL
webpage <- read_html(url)
# Extraire les dates des éléments <td>
dates <- webpage %>%
html_nodes('table tbody tr td span') %>%
html_text() %>%
str_trim()  # Supprimer les espaces supplémentaires
# Convertir les dates en objets Date
dates_converted <- dmy(dates)
# Afficher les dates converties
print(dates_converted)
# Lire les données
data <- read.csv("C:/Users/HP/Downloads/Predicting_Metal_Cost_with_R-master-20240318T152350Z-001/Predicting_Metal_Cost_with_R-master/dataexchanges/data_EUR_CNY.csv", header = TRUE)
head(data)
print(tail(data))
data$Date <- as.Date(data$Date)
data <- data[order(data$Date),  ]
##data <- head(data, n = nrow(data) - 22)
head(data)
print(tail(data))
# Ajuster le modèle ARIMA avec le meilleur ordre
fit <- Arima(data[,2], order = c(0, 2, 1))
# Ajuster les marges de la figure
par(mar = c(1, 4, 4, 2) + 0.1)
# Diagramme de diagnostic
tsdiag(fit)
# Prévision pour les 22 prochaines périodes
forecast <- forecast(fit, h = 22)
# Imprimer les 18 dernières valeurs des données réelles
print(tail(data[, 2], 18))
# Imprimer les prévisions
print(forecast)
# Liste des jours fériés européens pour 2024
public_holidays <- dates_converted
# Générer une séquence de dates pour les périodes prévisionnelles excluant les week-ends et les jours fériés
start_date <- as.Date(tail(data[, 1], 1)) + 1 # Incrémenter la date de début d'un jour
forecast_dates <- seq.Date(start_date, by = "day", length.out = 100) # Générer plus de dates initialement
# Filtrer les week-ends (samedi et dimanche) et les jours fériés
forecast_dates <- forecast_dates[!(weekdays(forecast_dates) %in% c("samedi", "dimanche"))]
forecast_dates <- forecast_dates[!(forecast_dates %in% public_holidays)]
# Prendre uniquement le nombre nécessaire de dates pour les périodes prévisionnelles
forecast_dates <- forecast_dates[1:length(forecast$mean)]
forecasted_data<-  forecasted_data[order(forecasted_data$Date), ]
forecasted_data<-  forecasted_data[order(forecasted_data$date), ]
# Combiner les valeurs prévisionnelles avec les dates
forecasted_data <- data.frame(Date = as.Date(forecast_dates), Forecast = as.numeric(forecast$mean))
print(forecasted_data)
# Sauvegarde des métriques dans un fichier spécifique
write.csv(forecasted_data, file = "C:/Users/HP/Downloads/Predicting_Metal_Cost_with_R-master-20240318T152350Z-001/Predicting_Metal_Cost_with_R-master/data/forecasted_22data_EUR_CNY.csv", row.names = FALSE)
# Charger les anciennes données prévisionnelles
if (file.exists("C:/Users/HP/Downloads/Predicting_Metal_Cost_with_R-master-20240318T152350Z-001/Predicting_Metal_Cost_with_R-master/data/forecasted_valuesEUR_CNY.csv")) {
old_forecasted_data <- read.csv("C:/Users/HP/Downloads/Predicting_Metal_Cost_with_R-master-20240318T152350Z-001/Predicting_Metal_Cost_with_R-master/data/forecasted_valuesEUR_CNY.csv", header = TRUE)
# Convertir la colonne Date de old_forecasted_data en type Date
old_forecasted_data$Date <- as.Date(old_forecasted_data$Date)
# Combiner les anciennes données avec les nouvelles
combined_forecasted_data <- bind_rows(old_forecasted_data, forecasted_data)
# Éliminer les doublons basés sur la colonne "Date"
combined_forecasted_data <- combined_forecasted_data %>% distinct(Date, .keep_all = TRUE)
combined_forecasted_data<-   combined_forecasted_data[order(combined_forecasted_data$Date), ]
# Enregistrer les données combinées dans un fichier CSV
write.csv(combined_forecasted_data, file = "C:/Users/HP/Downloads/Predicting_Metal_Cost_with_R-master-20240318T152350Z-001/Predicting_Metal_Cost_with_R-master/data/forecasted_valuesEUR_CNY.csv", row.names = FALSE)
} else {
# Si le fichier n'existe pas, enregistrer les nouvelles données
write.csv(forecasted_data, file = "C:/Users/HP/Downloads/Predicting_Metal_Cost_with_R-master-20240318T152350Z-001/Predicting_Metal_Cost_with_R-master/data/forecasted_valuesEUR_CNY.csv", row.names = FALSE)
}
# Lire les données prévisionnelles combinées
forecasted_data <- read.csv("C:/Users/HP/Downloads/Predicting_Metal_Cost_with_R-master-20240318T152350Z-001/Predicting_Metal_Cost_with_R-master/data/forecasted_valuesEUR_CNY.csv", header = TRUE)
print(forecasted_data)
data$Date <- as.Date(data$Date)
forecasted_data$Date <- as.Date(forecasted_data$Date)
library(forecast)
library(tseries)
library(ggplot2)
library(rvest)
library(dplyr)
library(stringr)
library(lubridate)
library(Metrics)
# Extraire les 22 derniers jours de données réelles
last_22_real <- tail(data, 22)
# Filtrer les prévisions pour correspondre aux dates des 22 derniers jours
last_22_forecast <- forecasted_data %>% filter(Date %in% last_22_real$Date)
print(last_22_real)
print(last_22_forecast)
# Combinaison des 22 dernières données réelles et des 22 dernières prévisions
combined_data <- cbind(last_22_real, last_22_forecast$Forecast)
# Renommer la colonne de prévisions
colnames(combined_data)[3] <- "Forecast"
# Sauvegarde dans un fichier CSV spécifique
write.csv(combined_data, file = "C:/Users/HP/Downloads/Predicting_Metal_Cost_with_R-master-20240318T152350Z-001/Predicting_Metal_Cost_with_R-master/data/last_real_and_forecasted_values_EUR_CNY.csv", row.names = FALSE)
# Calculer les métriques
mae_value <- mae(last_22_real[,2], last_22_forecast$Forecast)
rmse_value <- rmse(last_22_real[,2], last_22_forecast$Forecast)
r2_value <- cor(last_22_real[,2], last_22_forecast$Forecast)^2
pmae_value <- sum(abs(last_22_real[,2] - last_22_forecast$Forecast)) / sum(abs(last_22_real[,2]))
mse_value <- mse(last_22_real[,2], last_22_forecast$Forecast)
mape_value <- mape(last_22_real[,2], last_22_forecast$Forecast)
# Extraire la dernière date des prévisions
last_forecast_date <- tail(last_22_forecast$Date, 1)
# Afficher les résultats
cat("MAE:", mae_value, "\n")
cat("RMSE:", rmse_value, "\n")
cat("R²:", r2_value, "\n")
cat("PMAE:", pmae_value, "\n")
cat("MSE:", mse_value, "\n")
cat("MAPE:", mape_value, "\n")
cat("Last Forecast Date:", last_forecast_date, "\n")
# Création d'un data frame pour les métriques avec la dernière date des prévisions
metrics_data <- data.frame(Date = last_forecast_date,
MAE = mae_value,
RMSE = rmse_value,
MSE = mse_value,
MAPE = mape_value)
# Sauvegarde des métriques dans un fichier spécifique
write.csv(metrics_data, file = "C:/Users/HP/Downloads/Predicting_Metal_Cost_with_R-master-20240318T152350Z-001/Predicting_Metal_Cost_with_R-master/data/metrics_EUR_CNY.csv", row.names = FALSE)
# Charger les bibliothèques nécessaires
library(forecast)
library(tseries)
library(ggplot2)
library(rvest)
library(dplyr)
library(lubridate)
library(stringr)
library(Metrics)
# Lire les données
data <- read.csv("C:/Users/HP/Downloads/Predicting_Metal_Cost_with_R-master-20240318T152350Z-001/Predicting_Metal_Cost_with_R-master/data/cleaningdata.csv", header = TRUE)
head(data)
data <- data[order(data$date), ]
head(data)
print(tail(data))
##data <- head(data, n = nrow(data) - 3)
# Ajuster le modèle ARIMA avec le meilleur ordre
fit <-  Arima(data[,2] , xreg = data[, 3] , order = c(2, 1, 7))
# Ajuster les marges de la figure
par(mar = c(1, 4, 4, 2) + 0.1)
fitoil <-  auto.arima(data[, 3] )
forecastoil <- forecast(fitoil, h = 3)
# Plot diagnostics
tsdiag(fit)
# Forecast the next 20 periods
forecast <- forecast(fit  , xreg=forecastoil$mean , h = 3)
# Diagramme de diagnostic
tsdiag(fit)
# Imprimer les prévisions
print(forecast)
# Liste des jours fériés de la LME pour 2024
public_holidays <- as.Date(c(
"2024-03-29", "2024-03-28", # Good Friday
"2024-04-01",              # Easter Monday
"2024-05-06", "2024-05-07", # Early May Bank Holiday
"2024-05-27", "2024-05-28", # Spring Bank Holiday
"2024-08-26",              # Summer Bank Holiday
"2024-12-25", "2024-12-27", # Christmas Day
"2024-12-26", "2024-12-27", # Boxing Day
"2025-01-01", "2025-01-02"  # New Year's Day
))
# Générer une séquence de dates pour les périodes prévisionnelles excluant les week-ends et les jours fériés
start_date <- as.Date(tail(data[, 1], 1)) + 1 # Incrémenter la date de début d'un jour
forecast_dates <- seq.Date(start_date, by = "day", length.out = 100) # Générer plus de dates initialement
# Filtrer les week-ends (samedi et dimanche) et les jours fériés
forecast_dates <- forecast_dates[!(weekdays(forecast_dates) %in% c("Saturday", "Sunday"))]
forecast_dates <- forecast_dates[!forecast_dates %in% public_holidays]
# Prendre uniquement le nombre nécessaire de dates pour les périodes prévisionnelles
forecast_dates <- forecast_dates[1:length(forecast$mean)]
print(forecasted_data)
# Filtrer les week-ends (samedi et dimanche) et les jours fériés
forecast_dates <- forecast_dates[!(weekdays(forecast_dates)%in% c("Saturday", "Sunday"))]
print(forecasted_dates)
print(forecast_dates)
# Filtrer les week-ends (samedi et dimanche) et les jours fériés
forecast_dates <- forecast_dates[(weekdays(forecast_dates)%in% c("Saturday", "Sunday"))]
print(forecast_dates)
# Filtrer les week-ends (samedi et dimanche) et les jours fériés
forecast_dates <- forecast_dates[!(weekdays(forecast_dates)%in% c("Saturday", "Sunday"))]
print(forecast_dates)
forecast_dates <- seq.Date(start_date, by = "day", length.out = 100) # Générer plus de dates initialement
# Filtrer les week-ends (samedi et dimanche) et les jours fériés
forecast_dates <- forecast_dates[!(weekdays(forecast_dates)%in% c("Saturday", "Sunday"))]
print(forecast_dates)
# Filtrer les week-ends (samedi et dimanche) et les jours fériés
forecast_dates <- forecast_dates[!(weekdays(forecast_dates)%in% c("Saturday", "Sunday"))]
print(forecast_dates)
# Filtrer les week-ends (samedi et dimanche) et les jours fériés
forecast_dates <- forecast_dates[!(weekdays(forecast_dates) %in% c("Saturday", "Sunday"))]
print(forecast_dates)
# Charger les bibliothèques nécessaires
library(forecast)
library(tseries)
library(ggplot2)
library(rvest)
library(dplyr)
library(lubridate)
library(stringr)
library(Metrics)
# Lire les données
data <- read.csv("C:/Users/HP/Downloads/Predicting_Metal_Cost_with_R-master-20240318T152350Z-001/Predicting_Metal_Cost_with_R-master/data/cleaningdata.csv", header = TRUE)
head(data)
data <- data[order(data$date), ]
head(data)
print(tail(data))
##data <- head(data, n = nrow(data) - 3)
# Ajuster le modèle ARIMA avec le meilleur ordre
fit <-  Arima(data[,2] , xreg = data[, 3] , order = c(2, 1, 7))
# Ajuster les marges de la figure
par(mar = c(1, 4, 4, 2) + 0.1)
fitoil <-  auto.arima(data[, 3] )
forecastoil <- forecast(fitoil, h = 3)
# Plot diagnostics
tsdiag(fit)
# Forecast the next 20 periods
forecast <- forecast(fit  , xreg=forecastoil$mean , h = 3)
# Diagramme de diagnostic
tsdiag(fit)
# Imprimer les prévisions
print(forecast)
# Liste des jours fériés de la LME pour 2024
public_holidays <- as.Date(c(
"2024-03-29", "2024-03-28", # Good Friday
"2024-04-01",              # Easter Monday
"2024-05-06", "2024-05-07", # Early May Bank Holiday
"2024-05-27", "2024-05-28", # Spring Bank Holiday
"2024-08-26",              # Summer Bank Holiday
"2024-12-25", "2024-12-27", # Christmas Day
"2024-12-26", "2024-12-27", # Boxing Day
"2025-01-01", "2025-01-02"  # New Year's Day
))
# Générer une séquence de dates pour les périodes prévisionnelles excluant les week-ends et les jours fériés
start_date <- as.Date(tail(data[, 1], 1)) + 1 # Incrémenter la date de début d'un jour
forecast_dates <- seq.Date(start_date, by = "day", length.out = 100) # Générer plus de dates initialement
# Filtrer les week-ends (samedi et dimanche)
forecast_dates <- forecast_dates[!(weekdays(forecast_dates) %in% c("Saturday", "Sunday"))]
print(forecast_dates)
# Filtrer les jours fériés
forecast_dates <- forecast_dates[!forecast_dates %in% public_holidays]
# Afficher les dates filtrées
print(forecast_dates)
# Charger les bibliothèques nécessaires
library(forecast)
library(tseries)
library(ggplot2)
library(rvest)
library(dplyr)
library(lubridate)
library(stringr)
library(Metrics)
# Lire les données
data <- read.csv("C:/Users/HP/Downloads/Predicting_Metal_Cost_with_R-master-20240318T152350Z-001/Predicting_Metal_Cost_with_R-master/data/cleaningdata.csv", header = TRUE)
head(data)
data <- data[order(data$date), ]
head(data)
print(tail(data))
##data <- head(data, n = nrow(data) - 3)
# Ajuster le modèle ARIMA avec le meilleur ordre
fit <-  Arima(data[,2] , xreg = data[, 3] , order = c(2, 1, 7))
# Ajuster les marges de la figure
par(mar = c(1, 4, 4, 2) + 0.1)
fitoil <-  auto.arima(data[, 3] )
forecastoil <- forecast(fitoil, h = 3)
# Plot diagnostics
tsdiag(fit)
# Forecast the next 20 periods
forecast <- forecast(fit , xreg=forecastoil$mean , h = 3)
# Diagramme de diagnostic
tsdiag(fit)
# Imprimer les prévisions
print(forecast)
# Liste des jours fériés de la LME pour 2024
public_holidays <- as.Date(c(
"2024-03-29", "2024-03-28", # Good Friday
"2024-04-01",              # Easter Monday
"2024-05-06", "2024-05-07", # Early May Bank Holiday
"2024-05-27", "2024-05-28", # Spring Bank Holiday
"2024-08-26",              # Summer Bank Holiday
"2024-12-25", "2024-12-27", # Christmas Day
"2024-12-26", "2024-12-27", # Boxing Day
"2025-01-01", "2025-01-02"  # New Year's Day
))
# Générer une séquence de dates pour les périodes prévisionnelles excluant les week-ends et les jours fériés
start_date <- as.Date(tail(data[, 1], 1)) + 1 # Incrémenter la date de début d'un jour
forecast_dates <- seq.Date(start_date, by = "day", length.out = 100) # Générer plus de dates initialement
# Filtrer les week-ends (samedi et dimanche)
forecast_dates <- forecast_dates[!(weekdays(forecast_dates) %in% c("Saturday", "Sunday"))]
# Filtrer les jours fériés
forecast_dates <- forecast_dates[!forecast_dates %in% public_holidays]
# Afficher les dates filtrées
print(forecast_dates)
# Prendre uniquement le nombre nécessaire de dates pour les périodes prévisionnelles
forecast_dates <- forecast_dates[1:length(forecast$mean)]
print(forecasted_data)
# Combiner les valeurs prévisionnelles avec les dates
forecasted_data <- data.frame(date = as.Date(forecast_dates), Forecast = as.numeric(forecast$mean))
forecasted_data<-  forecasted_data[order(forecasted_data$date), ]
print(forecasted_data)
# Sauvegarde des données prévisionnelles dans un fichier CSV
write.csv(forecasted_data, file = "C:/Users/HP/Downloads/Predicting_Metal_Cost_with_R-master-20240318T152350Z-001/Predicting_Metal_Cost_with_R-master/data/forecasted_22data_CopperLME.csv", row.names = FALSE)
# Vérifier si le répertoire 'data' existe, sinon le créer
if (!dir.exists("data")) {
dir.create("data")
}
# Charger les anciennes données prévisionnelles
if (file.exists("C:/Users/HP/Downloads/Predicting_Metal_Cost_with_R-master-20240318T152350Z-001/Predicting_Metal_Cost_with_R-master/data/forecasted_valuesCopperLME.csv")) {
old_forecasted_data <- read.csv("C:/Users/HP/Downloads/Predicting_Metal_Cost_with_R-master-20240318T152350Z-001/Predicting_Metal_Cost_with_R-master/data/forecasted_valuesCopperLME.csv", header = TRUE)
# Convertir la colonne Date de old_forecasted_data en type Date
old_forecasted_data$date <- as.Date(old_forecasted_data$date)
# Combiner les anciennes données avec les nouvelles
combined_forecasted_data <- bind_rows(old_forecasted_data, forecasted_data)
# Éliminer les doublons basés sur la colonne "Date"
combined_forecasted_data <- combined_forecasted_data %>% distinct(date, .keep_all = TRUE)
combined_forecasted_data<-   combined_forecasted_data[order(combined_forecasted_data$date), ]
# Enregistrer les données combinées dans un fichier CSV
write.csv(combined_forecasted_data, file = "C:/Users/HP/Downloads/Predicting_Metal_Cost_with_R-master-20240318T152350Z-001/Predicting_Metal_Cost_with_R-master/data/forecasted_valuesCopperLME.csv", row.names = FALSE)
} else {
# Si le fichier n'existe pas, enregistrer les nouvelles données
write.csv(forecasted_data, file = "C:/Users/HP/Downloads/Predicting_Metal_Cost_with_R-master-20240318T152350Z-001/Predicting_Metal_Cost_with_R-master/data/forecasted_valuesCopperLME.csv", row.names = FALSE)
}
# Lire les données prévisionnelles combinées
forecasted_data <- read.csv("C:/Users/HP/Downloads/Predicting_Metal_Cost_with_R-master-20240318T152350Z-001/Predicting_Metal_Cost_with_R-master/data/forecasted_valuesCopperLME.csv", header = TRUE)
print(forecasted_data)
data$date <- as.Date(data$date)
forecasted_data$date <- as.Date(forecasted_data$date)
# Extraire les 22 derniers jours de données réelles
last_22_real <- tail(data[1:2], 9)
print(last_22_real)
last_22_real <-  last_22_real %>% filter(date %in% forecasted_data$date)
print(last_22_real)
# Filtrer les prévisions pour correspondre aux dates des 22 derniers jours
last_22_forecast <- forecasted_data %>% filter(date %in% last_22_real$date)
print(last_22_real)
print(last_22_forecast)
# Combinaison des 22 dernières données réelles et des 22 dernières prévisions
combined_data <- cbind(last_22_real, last_22_forecast$Forecast)
# Renommer la colonne de prévisions
colnames(combined_data)[3] <- "Forecast"
# Sauvegarde dans un fichier CSV spécifique
write.csv(combined_data, file = "C:/Users/HP/Downloads/Predicting_Metal_Cost_with_R-master-20240318T152350Z-001/Predicting_Metal_Cost_with_R-master/data/last_real_and_forecasted_values_CopperLME.csv", row.names = FALSE)
print(combined_data)
# Calculer les métriques
mae_value <- mae(last_22_real[, 2], last_22_forecast$Forecast)
rmse_value <- rmse(last_22_real[, 2], last_22_forecast$Forecast)
r2_value <- cor(last_22_real[, 2], last_22_forecast$Forecast)^2
pmae_value <- sum(abs(last_22_real[, 2] - last_22_forecast$Forecast)) / sum(abs(last_22_real[, 2]))
mse_value <- mse(last_22_real[, 2], last_22_forecast$Forecast)
mape_value <- mape(last_22_real[, 2], last_22_forecast$Forecast)
# Extraire la dernière date des prévisions
last_forecast_date <- tail(last_22_forecast$date, 1)
# Afficher les résultats
cat("MAE:", mae_value, "\n")
cat("RMSE:", rmse_value, "\n")
cat("R²:", r2_value, "\n")
cat("PMAE:", pmae_value, "\n")
cat("MSE:", mse_value, "\n")
cat("MAPE:", mape_value, "\n")
cat("Last Forecast Date:", last_forecast_date, "\n")
# Création d'un data frame pour les métriques avec la dernière date des prévisions
metrics_data <- data.frame(Date = last_forecast_date,
MAE = mae_value,
RMSE = rmse_value,
MSE = mse_value,
MAPE = mape_value)
# Sauvegarde des métriques dans un fichier spécifique
write.csv(metrics_data, file = "C:/Users/HP/Downloads/Predicting_Metal_Cost_with_R-master-20240318T152350Z-001/Predicting_Metal_Cost_with_R-master/data/metrics_CopperLME.csv", row.names = FALSE)
# Lire les données prévisionnelles combinées
forecasted_data <- read.csv("C:/Users/HP/Downloads/Predicting_Metal_Cost_with_R-master-20240318T152350Z-001/Predicting_Metal_Cost_with_R-master/data/forecasted_valuesCopperLME.csv", header = TRUE)
print(forecasted_data)
data$date <- as.Date(data$date)
forecasted_data$date <- as.Date(forecasted_data$date)
# Extraire les 22 derniers jours de données réelles
last_22_real <- tail(data[1:2], 9)
print(last_22_real)
# Lire les données
data <- read.csv("C:/Users/HP/Downloads/Predicting_Metal_Cost_with_R-master-20240318T152350Z-001/Predicting_Metal_Cost_with_R-master/data/cleaningdata.csv", header = TRUE)
head(data)
# Extraire les 22 derniers jours de données réelles
last_22_real <- tail(data[1:2], 9)
print(last_22_real)
library(mice)
library(dplyr)
library(readr)  # For writing CSV files
# Function to identify and replace outliers with NA and impute missing values
remove_outliers_and_impute <- function(data, variables) {
outlier_indices <- list()
for (variable in variables) {
# Identify indices of outliers
outliers <- boxplot(data[[variable]], plot = FALSE)$out
outlier_indices[[variable]] <- which(data[[variable]] %in% outliers)
# Replace outliers with NA
data[[variable]][outlier_indices[[variable]]] <- NA
}
# Perform imputation
imputed_data <- complete(mice(data))
return(imputed_data)
}
# List of datasets
datasets <- list(
USD_MXN = data_USD_MXN,
USD_MKD = data_USD_MKD,
USD_HNL = data_USD_HNL,
EUR_USD = data_EUR_USD,
EUR_TND = data_EUR_TND,
EUR_RSD = data_EUR_RSD,
EUR_RON = data_EUR_RON,
EUR_MXN = data_EUR_MXN,
EUR_MKD = data_EUR_MKD,
EUR_MAD = data_EUR_MAD,
EUR_CNY = data_EUR_CNY,
EUR_HNL = data_EUR_HNL,
USD_RON = data_USD_RON
)
# Variable of interest
variables_of_interest <- c("Price")
# Process datasets
imputed_datasets <- list()
for (dataset_name in names(datasets)) {
cat("Processing:", dataset_name, "\n")
data <- datasets[[dataset_name]]
# Execute the process twice
for (i in 1:2) {
data <- remove_outliers_and_impute(data, variables_of_interest)
}
imputed_datasets[[dataset_name]] <- data
# Evaluate results
summary(data)
remaining_outliers <- which(data$Price %in% boxplot(data$Price, plot = FALSE)$out)
cat("Number of remaining outliers in", dataset_name, ":", length(remaining_outliers), "\n\n")
}
# Charger les packages nécessaires
library(tidyr)
library(dplyr)
library(tidyverse)
library(lubridate)
library(ggplot2)
library(plotly)
library(reshape2) # for melt function
library(ggthemes)
library(infotheo)
# Charger les données
data_oil <-  read.csv("data/oil.csv", header = TRUE, sep = ";")
data_lme <-  read.csv("data/LME.csv", header = TRUE, sep = ";")
head(data_oil)
head(data_lme)
# Convertir les colonnes de dates en format Date
data_oil$Dateoil <- as.Date(data_oil$Dateoil, format = "%d/%m/%Y")
data_lme$DATElme <- as.Date(data_lme$DATElme, format = "%d/%m/%Y")
data_lme$Official.Ask.LME <- as.numeric(gsub(",", ".", data_lme$Official.Ask.LME))
data_oil$Cushing..OK.WTI.Spot.Price.FOB..Dollars.per.Barrel. <- as.numeric(gsub(",", ".", data_oil$Cushing..OK.WTI.Spot.Price.FOB..Dollars.per.Barrel.))
head(data_oil)
head(data_lme)
# Fusionner les deux ensembles de données
merged_data <- merge(data_oil, data_lme, by.x = "Dateoil", by.y = "DATElme", all = TRUE)
# Compléter les dates manquantes
#merged_data_complete <- merged_data %>%
#      complete(DateOIL = seq(min(DateOIL), max(DateOIL), by = "day"))
write_csv(merged_data, "data/datacl.csv")
# Afficher les données complètes
print(merged_data)
View(merged_data)
dim(merged_data)
str(merged_data)
tail(merged_data)
glimpse(merged_data)
unique(merged_data$Cushing..OK.WTI.Spot.Price.FOB..Dollars.per.Barrel.)
unique(merged_data$Official.Ask.LME)
# Compter les données manquantes dans chaque colonne
missing_valueoils <- sapply(merged_data$Cushing..OK.WTI.Spot.Price.FOB..Dollars.per.Barrel., function(x) sum(is.na(x)))
# Afficher le nombre de données manquantes dans chaque colonne
print(missing_valueoils)
# Compter les données manquantes dans chaque colonne
missing_valueLMEs <- sapply(merged_data$Official.Ask.LME, function(x) sum(is.na(x)))
# Afficher le nombre de données manquantes dans chaque colonne
print(missing_valueLMEs)
total_missingoil <- sum(is.na(merged_data$Cushing..OK.WTI.Spot.Price.FOB..Dollars.per.Barrel.))
# Afficher le nombre total de données manquantes
print(total_missingoil)
total_missingLME <- sum(is.na(merged_data$Official.Ask.LME))
# Afficher le nombre total de données manquantes
print(total_missingLME)
# Detecting anomalies using Z-scores
z_scores <- scale(data_oil$Price)
outliers <- which(abs(z_scores) > 3)
# Highlighting outliers on the plot
plot(data_oil$Date, data_oil$Price, type="l", col="blue", main="Oil Prices with Outliers", xlab="Date", ylab="Price")
points(data_oil$Date[outliers], data_oil$Price[outliers], col="red", pch=19)
